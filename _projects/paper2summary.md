---
layout: page
title: paper2summary
description: A resource-efficient RAG engine for scientific paper question answering 
importance: 1
category: "LLM/RAG/AI"
---

### Quick Summary

- Engineered a resource-efficient RAG engine for scientific paper question answering (QA) with precise source citations 
- Fine-tuned the Llama-3.2-1B model using LoRA, optimizing GPU utilization and elevating ROUGE scores by 28% for long context paper summarization 
- Delivered a lightweight desktop application with an intuitive UI using Ollama and Kotaemon, enabling cross-document QA, LLM-based reranking, and inline citation highlighting for an improved user experience 

### Video Demo
 <style>
    .video-container {
        position: relative;
        padding-bottom: 56.25%; /* 16:9 Aspect Ratio */
        height: 0;
        overflow: hidden;
    }
    .video-container iframe {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        border: none;
    }
</style>
<div class="video-container">
<iframe 
    src="https://www.youtube.com/embed/NsxGwMrflAE" 
    title="YouTube video player" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen>
</iframe>
</div>

For more detailed project information, please visit the GitHub repo: <https://github.com/gabe-zhang/paper2summary>